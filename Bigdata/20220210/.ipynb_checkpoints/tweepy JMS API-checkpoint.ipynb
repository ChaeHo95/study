{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd5295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58196a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = 'yYZ7GBu4iQd9SYbpMRTOvqssJ'\n",
    "CONSUMER_SECRET = 'yWXW08kPc35ygi0BnNByUBCGG5TnEoVZ9AsxGS9UVzVKGo4gaW'\n",
    "ACCESS_TOKEN_KEY = '1486551414822236162-BfSelTiGFomedeTry2CUQwHkNLmy7x'\n",
    "ACCES_TOKEN_SECRET = 'JaYHN0dYyJ8B8QwaGiTkpJfXVs1AY1Gvtn48eyttXbbdH'\n",
    "\n",
    "auth=tweepy.OAuthHandler(CONSUMER_KEY,CONSUMER_SECRET)\n",
    "\n",
    "auth.set_access_token(ACCESS_TOKEN_KEY,ACCES_TOKEN_SECRET )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcfc8cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "ì£¼ì‹ìŸì´ë“¤ì´ ê¹€ê±´í¬ ì£¼ê°€ì¡°ì‘ ì˜í˜¹ì— ëŒ€í•´ ê´€ëŒ€í•œ ê±° ì°¸ ì‹ ê¸°í•œ ì¼ì´ì•¼\n",
      "[]\n",
      "[]\n",
      "ì „ íˆ¬ìê·œëª¨ì— ë¹„í•´ì„œ ë°°ë‹¹ê¸ˆì„ ë§ì´ ë°›ì§„ ì•Šì§€ë§Œ, í•´ì™¸ì£¼ì‹ í•˜ì‹œëŠ”ë¶„ë“¤ ì •ë§ ëŒ€ë‹¨í•˜ë„¤ìš”.\n",
      "\n",
      "https://t.co/YP8adNDfWX\n",
      "[]\n",
      "[]\n",
      "ì—”ì†” ì£¼ì‹ì°½ ë³´ê³  í•œìˆ¨ ì‰¬ê³  ì˜¤ëŠ” ê¸¸ì„\n",
      "[{'screen_name': 'ShinnSamuel', 'name': 'ëˆˆë¬¼ì˜í˜¸ì†Œ: ê°œí˜ì´ ë¯¼ìƒì´ë‹¤', 'id': 4825716940, 'id_str': '4825716940', 'indices': [3, 15]}]\n",
      "[]\n",
      "RT @ShinnSamuel: ë”±ê±¸ë¦° ê¹€ê±´í¬ \n",
      "\n",
      "â€¢ìœ¤ì„ì—´, 2010 5ì›” ì´í›„ ì£¼ì‹ê±°ë˜ ì—†ì—ˆë‹¤-ê±°ì§“ë§\n",
      "â€¢KBS ë³´ë„: 2010 5ì›” ì´í›„ 40ì—¬ì°¨ë¡€ ê±°ë˜, ê±°ë˜ì´ì•¡ì˜ 7.7%ëŠ” ê¹€ê±´í¬ ê³„ì¢Œë¡œ ë“¤ì–´ê°”ë‹¤\n",
      "â€¢ê¹€ê±´í¬ ì§„ìˆ ë„ ê±°ì§“ë§\n",
      "ì–¼êµ´ ì´ë¦„ í•™ë ¥ ê²½ë ¥ ë­â€¦\n",
      "[]\n",
      "[{'text': 'ì£¼ê°€ì¡°ì‘_ì˜í˜¹', 'indices': [19, 27]}, {'text': 'KBS', 'indices': [45, 49]}]\n",
      "ìœ¤ì„ì—´ í›„ë³´ ë°°ìš°ì ê¹€ê±´í¬ ì”¨ì˜ â€˜#ì£¼ê°€ì¡°ì‘_ì˜í˜¹â€™ì´ ë‹¤ì‹œ ìˆ˜ë©´ ìœ„ë¡œ ë– ì˜¬ëë‹¤. #KBS \"êµ­ë¯¼ì˜í˜ ëŒ€ì„ ìº í”„ í•´ëª…ê³¼ ë‹¬ë¦¬, 5ì›” ì´í›„ ì£¼ì‹ ê±°ë˜ í™œë°œ\"â€¦ë¯¼ì£¼ë‹¹ \"ê¹€ê±´í¬, ì£¼ê°€ì¡°ì‘ ë‹¹ì‹œ ì „ì²´ ìœ í†µì£¼ì‹ì˜ 7.5â€¦ https://t.co/tMzWPDNJIn\n",
      "[]\n",
      "[]\n",
      "ì•„ì´ìŠ¤í¬ë¦¼ê°’ë²ŒëŸ¬\n",
      "ìƒˆë¡œìš´ì„¤ë¬¸ì¡°ì‚¬í”Œë«íŒì„ì°¾ì•„ë‚˜ì„œë‹¤\n",
      "í„° ë²…í„° ë²… .\n",
      "ì•„ë¬´ë˜ë„ì£¼ì‹ìœ¼ë¡œë²ˆì ì€ì—†ìœ¼ë‹ˆì¹¸ .\n",
      "[]\n",
      "[]\n",
      "ê¹€ê±´í¬ì”¨ê°€ ê²€ì°°ì´ íŒŒì•…í•œ ì£¼ê°€ì¡°ì‘ ì‹œê¸°ì— ê·¸ë™ì•ˆ ì•Œë ¤ì§€ì§€ ì•Šì€ ê³„ì¢Œ ë“±ì„ í†µí•´ 50ì–µì› ê°€ëŸ‰ ì£¼ì‹ê±°ë˜ë¥¼ í•œ ê²ƒìœ¼ë¡œ í™•ì¸ëë‹¤. ì „í˜•ì  ì¡°ì‘ ìˆ˜ë²•ì¸ â€˜í†µì •ë§¤ë§¤â€™ê°€ ì´ë¤„ì§„ ì •í™©ë„ ìˆë‹¤ê³  í•œë‹¤. \n",
      "â€œì£¼ê°€ì¡°ì‘ ì‹œê¸°ì—â€¦ https://t.co/qzjnmwJTd2\n",
      "[]\n",
      "[]\n",
      "'ë¯¸êµ­ì—ì„œ ì—°ë°© ì˜íšŒ ì˜ì›ê³¼ ê°€ì¡±ì˜ ì£¼ì‹ ë³´ìœ ì™€ ê±°ë˜ë¥¼ ê¸ˆì§€í•˜ë ¤ëŠ” ì›€ì§ì„ì´ íƒ„ë ¥ì„ ë°›ê³  ìˆë‹¤..\n",
      "\n",
      "2020ë…„ ë´„..ìƒë‹¹ìˆ˜ ì˜ì›ë“¤ì´..(ì½”ë¡œë‚˜ì— ê´€í•œ) ë¹„ê³µê°œ ë¸Œë¦¬í•‘ì„ ë°›ì€ ë’¤ ê¸°ì¡´ ë³´ìœ  ì£¼ì‹ì„ ëŒ€ëŸ‰ ë§¤ê°í•˜ê³ â€¦ https://t.co/47QkJyTobB\n",
      "[{'screen_name': 't4J7SpVswo4IOi6', 'name': 'ì½”ì½”', 'id': 1390121872012976129, 'id_str': '1390121872012976129', 'indices': [3, 19]}]\n",
      "[]\n",
      "RT @t4J7SpVswo4IOi6: ì§‘ë„ ì ˆë„ ì—†ì´ ì›”ì„¸ì‚´ë©´ì„œ 4ì²œë§Œì› ì´ì¬ëª… í€ë“œì— ë„£ì€ë‹¤ê³ ? ì£¼ì‹ì—ì„œ ë§í•œ ì´ìœ ê°€ ìˆë„¤ https://t.co/UJ5ym078pW\n",
      "[]\n",
      "[{'text': 'ì¡°ê±´ë§Œë‚¨', 'indices': [0, 5]}]\n",
      "#ì¡°ê±´ë§Œë‚¨ \n",
      "ã…ˆã„·ã…ã„´ \n",
      "ì—°ì˜ˆì¸íŒ¨ì…˜\n",
      "ì„œë¹„ìŠ¤ \n",
      "ì£¼ì‹ìë™ë§¤ë§¤\n",
      "ê²½ì‚°ì‹œ\n",
      "ê±°ì œë§›ì§‘\n",
      "ì˜¤í”„\n",
      "ì„¸ì¢…ê²½ê¸°ê°•ì›ê°•ë‚¨\n",
      "ê³ ì¶”\n",
      "ë¦°ë„¨ìŠ¤ì»¤íŠ¸ \n",
      "ë¬´ì•ˆêµ° \n",
      "ì„œìš¸ë¶€ì‚°ëŒ€êµ¬ì¸ì²œ\n",
      "ì¢†ì§‘\n",
      " 9015SK623FE2VU2\n",
      "[{'screen_name': 'ryu7230', 'name': 'ì¦ê¸°ë©° ì‚°ë‹¤ ^^', 'id': 397908286, 'id_str': '397908286', 'indices': [3, 11]}]\n",
      "[]\n",
      "RT @ryu7230: ê¹€ê±´í¬ 2010ë…„ 5ì›” ì´í›„ ì£¼ì‹ ê±°ë˜ ì—†ë‹¤ë”ë‹ˆâ€¦40ì—¬ ê±´ í™•ì¸\n",
      "\n",
      "ìœ¤ì„ì—´ì€ ê¹€ê±´í¬ê°€ ë„ì´ì¹˜ëª¨í„°ìŠ¤ ì£¼ì‹ì„ ê±°ë˜í•œ ê²ƒì€ ë§ì§€ë§Œ ì£¼ê°€ ì¡°ì‘ ë²”í–‰ ì´ì „ì´ë¼ ë²”ì£„ì™€ ë¬´ê´€í•˜ë‹¤ê³  í•´ëª…í•´ ì™”ë‹¤ ê·¸ëŸ¬ë‚˜ å°¹ì´ ê³µê°œí•œ ì‹ í•œì¦ê¶Œ ê³„ì¢Œê°€ ì•„ë‹Œ DSâ€¦\n",
      "[{'screen_name': 'ae_seohyun', 'name': 'ì„œí˜„áƒ¦', 'id': 1451079193878413312, 'id_str': '1451079193878413312', 'indices': [3, 14]}]\n",
      "[{'text': 'Follow', 'indices': [69, 76]}, {'text': 'RT', 'indices': [77, 80]}]\n",
      "RT @ae_seohyun: â­ï¸ 200ê´„ ê¸°ë…(?) ê³§ ìƒì¼ì´ë‹ˆê¹Œ(?) ìš©ëˆ ë°›ì•„ì„œ (?) ì—´ê³  ì‹¶ì–´ì„œ ì—¬ëŠ” ì²« ì´ë²µğŸŒŸ\n",
      "\n",
      "#Follow+#RT  1ëª… ë½‘ì•„ì„œ 3.0 ë“œë¦½ë‹ˆë‹¹ã…‡\n",
      "íŠ¸ì¹œ í•œì • X íŒ¬ë¤ ìƒê´€ X ì¼íšŒì„± íŒ” X \n",
      "\n",
      "ì œ ëˆì€ í•™êµ ì…í•™í•˜ë©´ ì£¼â€¦\n",
      "[{'screen_name': 'talkingCorea', 'name': 'ì•Œì½©ë‹¬ì½©', 'id': 182253413, 'id_str': '182253413', 'indices': [3, 16]}]\n",
      "[]\n",
      "RT @talkingCorea: ê¹€ê±´í¬, 2010ë…„ 5ì›” ì´í›„ ì£¼ì‹ ê±°ë˜ ì—†ë‹¤ë”ë‹ˆ..40ì—¬ ê±´ í™•ì¸\n",
      "\n",
      "ì´ê²Œë“¤í†µë‚˜ë‹ˆ..ì–´ì œ ë¶€í„° ìœ¤ë–¡ê²€ì´\n",
      "ë¬´ì‘ì • ë¬¸ì¬ì¸ì •ë¶€ ì íë©ì–´ë¦¬ë¼í•˜ë©°\n",
      "ë¬´í„±ëŒ€ê³  ê°œê´‘ì§€ë„í•˜ê¸°ì‹œì‘í•˜ë„¤!\n",
      " https://t.co/eJayae9vbg\n",
      "[]\n",
      "[]\n",
      "ìŠ¤íƒ€í‚¹ ë¡±ë‹¤ë¦¬ ì‚´ìŠ¤ ìœ í˜¹ í™”ëˆí•œë°¤ í‹°íŒ¬í‹° ê³ ì–‘ì´ìì„¸ ì£¼ì‹ ì¡°ê±´ë§Œë‚¨ ì„¹íŠ¸\n",
      " Y5IOD06DH\n",
      "[]\n",
      "[]\n",
      "ë§Œë‘\n",
      "ë…¸ì•”ì§¤ì‹œí¥ë²¤ì¸ \n",
      "í˜œí™”\n",
      "ì„ ë¦‰ì—­ì…”ì¸ ë£¸\n",
      "ì„œìš¸ì…”ì¸ ë£¸\n",
      "ë¨¹íŠ€ê²€ì¦\n",
      "ê°•ë‚¨ì—­ë”í‚¹\n",
      "ì§€ì—­\n",
      "ì»¤ë‹ \n",
      "ì¤‘ê³¡\n",
      "ì˜¤ë°ë§ˆí”¼ê²Œì£¼ì‹íˆ¬ìë¹„ë²•\n",
      "ê°€ì„íŒ¨ë””\n",
      "ì†Œë§¥ì—¬í–‰ì—ë¯¸ì¹˜ë‹¤\n",
      "ì¡°ê±´ë§Œë‚¨\n",
      " 68DKF1974576L9A9\n"
     ]
    }
   ],
   "source": [
    "api=tweepy.API(auth)\n",
    "\n",
    "keyword='ì£¼ì‹'\n",
    "tweets=api.search(keyword)\n",
    "\n",
    "for tweet in tweets:\n",
    "    print(tweet.entities['user_mentions'])\n",
    "    print(tweet.entities['hashtags'])\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54cb103",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "\n",
    "columns = ['created','tweet_text']\n",
    "df=pd.DataFrame(columns=columns)\n",
    "\n",
    "max_tweets=1000\n",
    "searched_tweets=[status for status in tweepy.Cursor(api.search,q=keyword).items(max_tweets)]\n",
    "\n",
    "for tweet in searched_tweets:\n",
    "    tweet_json=tweet._json\n",
    "    tweet_text=tweet_json['text']\n",
    "    created=tweet_json['created_at']\n",
    "    row=[created,tweet_text]\n",
    "    series=pd.Series(row,index=df.columns)\n",
    "    df=df.append(series,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_cleaning(text):\n",
    "    hangul=re.compile('[^ ã„±-ã…£ ê°€-í£]+')\n",
    "    result=hangul.sub('',text)\n",
    "    return result\n",
    "\n",
    "df['ko_text'] = df['tweet_text'].apply(lambda x: text_cleaning(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f007bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "korean_stopwords_path = \"korean_stopwords.txt\"\n",
    "with open(korean_stopwords_path, encoding='utf8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip() for x in stopwords] # strip()ìœ¼ë¡œ ê³µë°± ë° ì¤„ë°”ê¿ˆ ì œê±°\n",
    "\n",
    "# í’ˆì‚¬ ì¤‘ ëª…ì‚¬ë§Œ ì¶”ì¶œí•˜ì—¬ í•œê¸€ì í‚¤ì›Œë“œ ë° ë¶ˆìš©ì–´ ì œê±°\n",
    "# Okt(Open Korean Text)ëŠ” íŠ¸ìœ„í„°ì—ì„œ ë§Œë“  ì˜¤í”ˆì†ŒìŠ¤ í•œêµ­ì–´ ì²˜ë¦¬ê¸°ì¸ twitter-korean-textë¥¼ ì´ì–´ë°›ì•„ ë§Œë“¤ê³  ìˆëŠ” í”„ë¡œì íŠ¸\n",
    "\n",
    "def get_nouns(x):\n",
    "    # ëª…ì‚¬ë§Œ ì¶”ì¶œ\n",
    "    nouns_tagger = Okt() # Okt()í´ë˜ìŠ¤ ì„ ì–¸\n",
    "    nouns = nouns_tagger.nouns(x)\n",
    "    \n",
    "    # í•œê¸€ì í‚¤ì›Œë“œ ì œê±°\n",
    "    nouns = [noun for noun in nouns if len(noun) > 1]\n",
    "    \n",
    "    # ë¶ˆìš©ì–´ë¥¼ ì œê±°\n",
    "    nouns = [noun for noun in nouns if noun not in stopwords]\n",
    "    \n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2582c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f319a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â€˜ko_textâ€™ í”¼ì²˜ì— get_nouns() í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ë¶ˆìš©ì–´ ë° í•œê¸€ìë¥¼ ì œê±°í•œ ëª…ì‚¬ ì¶”ì¶œí•˜ì—¬ 'nouns' í”¼ì²˜ ìƒì„±\n",
    "df['nouns'] = df['ko_text'].apply(lambda x:get_nouns(x))\n",
    "print(df.shape) # í–‰ê³¼ ì—´ì˜ ê°¯ìˆ˜ë¥¼ íŠœí”Œë¡œ ë°˜í™˜\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ddf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install apyori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fdfd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "\n",
    "transactions=[\n",
    "    ['íŒ¨ì…˜','ë¸”ë™'],\n",
    "    ['íŒ¨ì…˜','ì„¸íŠ¸'],\n",
    "    ['íŒ¨ì…˜','ëª…í’ˆ','ìœ í–‰']\n",
    "]\n",
    "\n",
    "results=list(apriori(transactions))\n",
    "for result in  results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e32b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ì§€ì§€ë„0.5,ì‹ ë¢°ë„0.6í–¥ìƒë„1.0ì´ìƒ, ê·œì¹™ì˜ í¬ê¸°ê°€ 2 ì´í•˜ì¸ ê·œì¹™ì¶”ì¶œ\n",
    "list(apriori(transactions,min_support=0.5,min_confidence=0.6,min_lift=1.0,max_length=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df402fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = df['nouns'].tolist()\n",
    "#transactions=[transaction for transaction in transactions if transaction]\n",
    "print(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=list(apriori(transactions,min_support=0.05,min_confidence=0.1,min_lift=5,max_length=2))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40552f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['source','target','support']\n",
    "network_df=pd.DataFrame(columns=columns)\n",
    "\n",
    "for result in results:\n",
    "    if len(result.items)==2:\n",
    "        items=[x for x in result.items]\n",
    "        row=[items[0],items[1],result.support]\n",
    "        series=pd.Series(row,index=network_df.columns)\n",
    "        network_df=network_df.append(series,ignore_index=True)\n",
    "network_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db87d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_corpus=\"\".join(df['ëŒ“ê¸€'].tolist())\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "# ëª…ì‚¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œ, ë¹ˆë„ìˆ˜ ê³„ì‚°\n",
    "nouns_tagger = Okt()\n",
    "nouns=nouns_tagger.nouns(tweet_corpus)\n",
    "count=Counter(nouns)\n",
    "# í•œê¸€ì í‚¤ì›Œë“œë¥¼ ì œê±°\n",
    "remove_char_counter=Counter({x:count[x]for x in count if len(x)>1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‚¤ì›Œë“œì™€ í‚¤ì›Œë“œ ë¹ˆë„ ì ìˆ˜ë¥¼ â€˜nodeâ€™, â€˜nodesizeâ€™ ë¼ëŠ” ë°ì´í„° í”„ë ˆì„ì˜ í”¼ì²˜ë¡œ ìƒì„±\n",
    "node_df=pd.DataFrame(remove_char_counter.items(),columns=['node','nodesize'])\n",
    "#node=node_df[node_df['nodesize']>=50] # ì‹œê°í™”ì˜ í¸ì˜ë¥¼ ìœ„í•´ â€˜nodesizeâ€™ 50 ì´í•˜ëŠ” ì œê±°í•©ë‹ˆë‹¤.\n",
    "node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "plt.figure(figsize=(25,25))\n",
    "\n",
    "# networkx ê·¸ë˜í”„ ê°ì²´ë¥¼ ìƒì„±\n",
    "G = nx.Graph()\n",
    "\n",
    "# node_dfì˜ í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ë¥¼ ë°ì´í„°ë¡œ í•˜ì—¬, ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ì˜ â€˜ë…¸ë“œâ€™ ì—­í• ì„ í•˜ëŠ” ì›ì„ ìƒì„±\n",
    "for index, row in node_df.iterrows():\n",
    "    G.add_node(row['node'], nodesize=row['nodesize'])\n",
    "    \n",
    "# network_dfì˜ ì—°ê´€ ë¶„ì„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ì˜ â€˜ê´€ê³„â€™ ì—­í• ì„ í•˜ëŠ” ì„ ì„ ìƒì„±\n",
    "for index, row in network_df.iterrows():\n",
    "    G.add_weighted_edges_from([(row['source'], row['target'], row['support'])])\n",
    "    \n",
    "# ê·¸ë˜í”„ ë””ìì¸ê³¼ ê´€ë ¨ëœ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •\n",
    "pos = nx.spring_layout(G, k=0.6, iterations=50)\n",
    "# nx.draw(G, pos=pos)\n",
    "\n",
    "sizes = [G.nodes[node]['nodesize']*5 for node in G]    \n",
    "\n",
    "nx.draw(G, pos=pos, node_size=sizes)\n",
    "\n",
    "\n",
    "# Windows ì‚¬ìš©ìëŠ” AppleGothic ëŒ€ì‹ ,'Malgun Gothic'. ê·¸ ì™¸ OSëŠ” OSì—ì„œ í•œê¸€ì„ ì§€ì›í•˜ëŠ” ê¸°ë³¸ í°íŠ¸ë¥¼ ì…ë ¥\n",
    "# nx.draw_networkx_labels(G, pos=pos, font_family='NanumGothic', font_size=25)\n",
    "nx.draw_networkx_labels(G, pos=pos, font_family='Malgun Gothic', font_size=25)\n",
    "\n",
    "# ê·¸ë˜í”„ë¥¼ ì¶œë ¥\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
