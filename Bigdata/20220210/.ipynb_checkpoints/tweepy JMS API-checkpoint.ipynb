{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd5295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58196a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = 'yYZ7GBu4iQd9SYbpMRTOvqssJ'\n",
    "CONSUMER_SECRET = 'yWXW08kPc35ygi0BnNByUBCGG5TnEoVZ9AsxGS9UVzVKGo4gaW'\n",
    "ACCESS_TOKEN_KEY = '1486551414822236162-BfSelTiGFomedeTry2CUQwHkNLmy7x'\n",
    "ACCES_TOKEN_SECRET = 'JaYHN0dYyJ8B8QwaGiTkpJfXVs1AY1Gvtn48eyttXbbdH'\n",
    "\n",
    "auth=tweepy.OAuthHandler(CONSUMER_KEY,CONSUMER_SECRET)\n",
    "\n",
    "auth.set_access_token(ACCESS_TOKEN_KEY,ACCES_TOKEN_SECRET )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcfc8cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "주식쟁이들이 김건희 주가조작 의혹에 대해 관대한 거 참 신기한 일이야\n",
      "[]\n",
      "[]\n",
      "전 투자규모에 비해서 배당금을 많이 받진 않지만, 해외주식 하시는분들 정말 대단하네요.\n",
      "\n",
      "https://t.co/YP8adNDfWX\n",
      "[]\n",
      "[]\n",
      "엔솔 주식창 보고 한숨 쉬고 오는 길임\n",
      "[{'screen_name': 'ShinnSamuel', 'name': '눈물의호소: 개혁이 민생이다', 'id': 4825716940, 'id_str': '4825716940', 'indices': [3, 15]}]\n",
      "[]\n",
      "RT @ShinnSamuel: 딱걸린 김건희 \n",
      "\n",
      "•윤석열, 2010 5월 이후 주식거래 없었다-거짓말\n",
      "•KBS 보도: 2010 5월 이후 40여차례 거래, 거래총액의 7.7%는 김건희 계좌로 들어갔다\n",
      "•김건희 진술도 거짓말\n",
      "얼굴 이름 학력 경력 뭐…\n",
      "[]\n",
      "[{'text': '주가조작_의혹', 'indices': [19, 27]}, {'text': 'KBS', 'indices': [45, 49]}]\n",
      "윤석열 후보 배우자 김건희 씨의 ‘#주가조작_의혹’이 다시 수면 위로 떠올랐다. #KBS \"국민의힘 대선캠프 해명과 달리, 5월 이후 주식 거래 활발\"…민주당 \"김건희, 주가조작 당시 전체 유통주식의 7.5… https://t.co/tMzWPDNJIn\n",
      "[]\n",
      "[]\n",
      "아이스크림값벌러\n",
      "새로운설문조사플랫펌을찾아나서다\n",
      "터 벅터 벅 .\n",
      "아무래도주식으로번적은없으니칸 .\n",
      "[]\n",
      "[]\n",
      "김건희씨가 검찰이 파악한 주가조작 시기에 그동안 알려지지 않은 계좌 등을 통해 50억원 가량 주식거래를 한 것으로 확인됐다. 전형적 조작 수법인 ‘통정매매’가 이뤄진 정황도 있다고 한다. \n",
      "“주가조작 시기에… https://t.co/qzjnmwJTd2\n",
      "[]\n",
      "[]\n",
      "'미국에서 연방 의회 의원과 가족의 주식 보유와 거래를 금지하려는 움직임이 탄력을 받고 있다..\n",
      "\n",
      "2020년 봄..상당수 의원들이..(코로나에 관한) 비공개 브리핑을 받은 뒤 기존 보유 주식을 대량 매각하고… https://t.co/47QkJyTobB\n",
      "[{'screen_name': 't4J7SpVswo4IOi6', 'name': '코코', 'id': 1390121872012976129, 'id_str': '1390121872012976129', 'indices': [3, 19]}]\n",
      "[]\n",
      "RT @t4J7SpVswo4IOi6: 집도 절도 없이 월세살면서 4천만원 이재명 펀드에 넣은다고? 주식에서 망한 이유가 있네 https://t.co/UJ5ym078pW\n",
      "[]\n",
      "[{'text': '조건만남', 'indices': [0, 5]}]\n",
      "#조건만남 \n",
      "ㅈㄷㅁㄴ \n",
      "연예인패션\n",
      "서비스 \n",
      "주식자동매매\n",
      "경산시\n",
      "거제맛집\n",
      "오프\n",
      "세종경기강원강남\n",
      "고추\n",
      "린넨스커트 \n",
      "무안군 \n",
      "서울부산대구인천\n",
      "좆집\n",
      " 9015SK623FE2VU2\n",
      "[{'screen_name': 'ryu7230', 'name': '즐기며 산다 ^^', 'id': 397908286, 'id_str': '397908286', 'indices': [3, 11]}]\n",
      "[]\n",
      "RT @ryu7230: 김건희 2010년 5월 이후 주식 거래 없다더니…40여 건 확인\n",
      "\n",
      "윤석열은 김건희가 도이치모터스 주식을 거래한 것은 맞지만 주가 조작 범행 이전이라 범죄와 무관하다고 해명해 왔다 그러나 尹이 공개한 신한증권 계좌가 아닌 DS…\n",
      "[{'screen_name': 'ae_seohyun', 'name': '서현ღ', 'id': 1451079193878413312, 'id_str': '1451079193878413312', 'indices': [3, 14]}]\n",
      "[{'text': 'Follow', 'indices': [69, 76]}, {'text': 'RT', 'indices': [77, 80]}]\n",
      "RT @ae_seohyun: ⭐️ 200괄 기념(?) 곧 생일이니까(?) 용돈 받아서 (?) 열고 싶어서 여는 첫 이벵🌟\n",
      "\n",
      "#Follow+#RT  1명 뽑아서 3.0 드립니당ㅇ\n",
      "트친 한정 X 팬덤 상관 X 일회성 팔 X \n",
      "\n",
      "제 돈은 학교 입학하면 주…\n",
      "[{'screen_name': 'talkingCorea', 'name': '알콩달콩', 'id': 182253413, 'id_str': '182253413', 'indices': [3, 16]}]\n",
      "[]\n",
      "RT @talkingCorea: 김건희, 2010년 5월 이후 주식 거래 없다더니..40여 건 확인\n",
      "\n",
      "이게들통나니..어제 부터 윤떡검이\n",
      "무작정 문재인정부 적폐덩어리라하며\n",
      "무턱대고 개광지랄하기시작하네!\n",
      " https://t.co/eJayae9vbg\n",
      "[]\n",
      "[]\n",
      "스타킹 롱다리 살스 유혹 화끈한밤 티팬티 고양이자세 주식 조건만남 섹트\n",
      " Y5IOD06DH\n",
      "[]\n",
      "[]\n",
      "만두\n",
      "노암짤시흥벤츠\n",
      "혜화\n",
      "선릉역셔츠룸\n",
      "서울셔츠룸\n",
      "먹튀검증\n",
      "강남역더킹\n",
      "지역\n",
      "커닐 \n",
      "중곡\n",
      "오데마피게주식투자비법\n",
      "가을패디\n",
      "소맥여행에미치다\n",
      "조건만남\n",
      " 68DKF1974576L9A9\n"
     ]
    }
   ],
   "source": [
    "api=tweepy.API(auth)\n",
    "\n",
    "keyword='주식'\n",
    "tweets=api.search(keyword)\n",
    "\n",
    "for tweet in tweets:\n",
    "    print(tweet.entities['user_mentions'])\n",
    "    print(tweet.entities['hashtags'])\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54cb103",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "\n",
    "columns = ['created','tweet_text']\n",
    "df=pd.DataFrame(columns=columns)\n",
    "\n",
    "max_tweets=1000\n",
    "searched_tweets=[status for status in tweepy.Cursor(api.search,q=keyword).items(max_tweets)]\n",
    "\n",
    "for tweet in searched_tweets:\n",
    "    tweet_json=tweet._json\n",
    "    tweet_text=tweet_json['text']\n",
    "    created=tweet_json['created_at']\n",
    "    row=[created,tweet_text]\n",
    "    series=pd.Series(row,index=df.columns)\n",
    "    df=df.append(series,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_cleaning(text):\n",
    "    hangul=re.compile('[^ ㄱ-ㅣ 가-힣]+')\n",
    "    result=hangul.sub('',text)\n",
    "    return result\n",
    "\n",
    "df['ko_text'] = df['tweet_text'].apply(lambda x: text_cleaning(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f007bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "korean_stopwords_path = \"korean_stopwords.txt\"\n",
    "with open(korean_stopwords_path, encoding='utf8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip() for x in stopwords] # strip()으로 공백 및 줄바꿈 제거\n",
    "\n",
    "# 품사 중 명사만 추출하여 한글자 키워드 및 불용어 제거\n",
    "# Okt(Open Korean Text)는 트위터에서 만든 오픈소스 한국어 처리기인 twitter-korean-text를 이어받아 만들고 있는 프로젝트\n",
    "\n",
    "def get_nouns(x):\n",
    "    # 명사만 추출\n",
    "    nouns_tagger = Okt() # Okt()클래스 선언\n",
    "    nouns = nouns_tagger.nouns(x)\n",
    "    \n",
    "    # 한글자 키워드 제거\n",
    "    nouns = [noun for noun in nouns if len(noun) > 1]\n",
    "    \n",
    "    # 불용어를 제거\n",
    "    nouns = [noun for noun in nouns if noun not in stopwords]\n",
    "    \n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2582c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f319a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‘ko_text’ 피처에 get_nouns() 함수를 적용하여 불용어 및 한글자를 제거한 명사 추출하여 'nouns' 피처 생성\n",
    "df['nouns'] = df['ko_text'].apply(lambda x:get_nouns(x))\n",
    "print(df.shape) # 행과 열의 갯수를 튜플로 반환\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ddf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install apyori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fdfd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "\n",
    "transactions=[\n",
    "    ['패션','블랙'],\n",
    "    ['패션','세트'],\n",
    "    ['패션','명품','유행']\n",
    "]\n",
    "\n",
    "results=list(apriori(transactions))\n",
    "for result in  results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e32b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 지지도0.5,신뢰도0.6향상도1.0이상, 규칙의 크기가 2 이하인 규칙추출\n",
    "list(apriori(transactions,min_support=0.5,min_confidence=0.6,min_lift=1.0,max_length=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df402fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = df['nouns'].tolist()\n",
    "#transactions=[transaction for transaction in transactions if transaction]\n",
    "print(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=list(apriori(transactions,min_support=0.05,min_confidence=0.1,min_lift=5,max_length=2))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40552f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['source','target','support']\n",
    "network_df=pd.DataFrame(columns=columns)\n",
    "\n",
    "for result in results:\n",
    "    if len(result.items)==2:\n",
    "        items=[x for x in result.items]\n",
    "        row=[items[0],items[1],result.support]\n",
    "        series=pd.Series(row,index=network_df.columns)\n",
    "        network_df=network_df.append(series,ignore_index=True)\n",
    "network_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db87d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_corpus=\"\".join(df['댓글'].tolist())\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "# 명사 키워드를 추출, 빈도수 계산\n",
    "nouns_tagger = Okt()\n",
    "nouns=nouns_tagger.nouns(tweet_corpus)\n",
    "count=Counter(nouns)\n",
    "# 한글자 키워드를 제거\n",
    "remove_char_counter=Counter({x:count[x]for x in count if len(x)>1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드와 키워드 빈도 점수를 ‘node’, ‘nodesize’ 라는 데이터 프레임의 피처로 생성\n",
    "node_df=pd.DataFrame(remove_char_counter.items(),columns=['node','nodesize'])\n",
    "#node=node_df[node_df['nodesize']>=50] # 시각화의 편의를 위해 ‘nodesize’ 50 이하는 제거합니다.\n",
    "node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "plt.figure(figsize=(25,25))\n",
    "\n",
    "# networkx 그래프 객체를 생성\n",
    "G = nx.Graph()\n",
    "\n",
    "# node_df의 키워드 빈도수를 데이터로 하여, 네트워크 그래프의 ‘노드’ 역할을 하는 원을 생성\n",
    "for index, row in node_df.iterrows():\n",
    "    G.add_node(row['node'], nodesize=row['nodesize'])\n",
    "    \n",
    "# network_df의 연관 분석 데이터를 기반으로, 네트워크 그래프의 ‘관계’ 역할을 하는 선을 생성\n",
    "for index, row in network_df.iterrows():\n",
    "    G.add_weighted_edges_from([(row['source'], row['target'], row['support'])])\n",
    "    \n",
    "# 그래프 디자인과 관련된 파라미터를 설정\n",
    "pos = nx.spring_layout(G, k=0.6, iterations=50)\n",
    "# nx.draw(G, pos=pos)\n",
    "\n",
    "sizes = [G.nodes[node]['nodesize']*5 for node in G]    \n",
    "\n",
    "nx.draw(G, pos=pos, node_size=sizes)\n",
    "\n",
    "\n",
    "# Windows 사용자는 AppleGothic 대신,'Malgun Gothic'. 그 외 OS는 OS에서 한글을 지원하는 기본 폰트를 입력\n",
    "# nx.draw_networkx_labels(G, pos=pos, font_family='NanumGothic', font_size=25)\n",
    "nx.draw_networkx_labels(G, pos=pos, font_family='Malgun Gothic', font_size=25)\n",
    "\n",
    "# 그래프를 출력\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
